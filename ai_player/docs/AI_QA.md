# AI_QA Bot Codebase Summary

This document provides a technical overview of the `ai_player` codebase, designed for experienced developers.

## 1. Main Entry Point and Control Flow

The main entry point for the AI_QA bot is `ai_player/main.py`.

**Startup/Control Flow:**
1.  **Configuration Loading:** `main.py` loads settings from `config.json` using the `Config` class.
2.  **Logging Setup:** Configures logging to a file (`ai_player.log`) and console.
3.  **Signal Handling:** Sets up `Ctrl+C` (SIGINT) for graceful shutdown.
4.  **State Management:** Initializes `StateManager` to load/save the bot's persistent state from `state.json`.
5.  **Schema Loading:** Parses `docs/PROTOCOL.v2.md` to load and cache command schemas, used for payload validation.
6.  **Bug Reporting:** Initializes `BugReporter` for structured bug logging, including new features for deduplication and regression test generation.
7.  **Game Connection:** Establishes a TCP connection to the game server via `GameConnection`.
8.  **Bandit Policy:** Initializes `BanditPolicy` for action selection and Q-value updates.
9.  **Finite State Planner:** Initializes `FiniteStatePlanner`, which orchestrates the bot's high-level behavior.
10. **Main Loop:** Enters a continuous loop:
    *   Checks and re-establishes game connection if lost.
    *   Processes all incoming server responses via `process_responses`.
    *   Calculates and applies rewards to the bandit policy via `calculate_and_apply_reward`.
    *   Checks for "out of turns" cooldown; if active, pauses execution.
    *   Prioritizes and executes any LLM-suggested recovery command.
    *   Calls `planner.get_next_command()` to determine the next action.
    *   Sends the chosen command to the game server.
    *   Introduces a small delay to prevent busy-waiting.
11. **Shutdown:** On `SIGINT`, saves the state and closes the game connection.

## 2. Module/File Responsibility Split

*   **`main.py`**: Orchestrates the entire bot. Handles startup, main loop, game connection, state management, response processing, and high-level error recovery (including LLM fallback).
*   **`planner.py`**: Implements the bot's decision-making logic. Contains the `FiniteStatePlanner` class, which manages the bot's current "stage" (bootstrap, survey, explore, exploit), defines preconditions for actions, builds command payloads, and selects the next action using the `BanditPolicy`.
*   **`state_manager.py` (Implicitly in `main.py` for now)**: Manages the bot's persistent state (e.g., current location, cargo, credits, visited sectors, cached prices, Q-tables). Handles loading from and saving to `state.json`.
*   **`game_connection.py` (Implicitly in `main.py` for now)**: Manages the TCP connection to the game server, sending commands and receiving raw responses.
*   **`bug_reporter.py`**: Handles the structured reporting of bugs and invariant failures. Now includes:
    *   **Deduplication:** Prevents duplicate bug reports using a hash of key bug details.
    *   **Regression Test Generation:** Automatically writes Python scripts (`test_BUGHASH.py`) that can replay the exact sequence of commands leading to a bug, aiding in reproduction and fixing.
    *   **LLM Oracle Analysis:** Integrates with an LLM to provide an analysis of the bug and suggest potential recovery commands, enhancing the bug report with AI insights.
*   **`bandit_policy.py`**: Implements the multi-armed bandit algorithm (epsilon-greedy) for action selection and Q-value updates based on rewards. Manages Q-tables and N-tables.
*   **`parse_protocol.py`**: Parses the `PROTOCOL.v2.md` markdown file to extract command schemas, which are then used for payload validation.

## 3. Data Flow Between Components

**Inputs:**
*   `config.json`: Initial configuration parameters.
*   `state.json`: Persistent bot state from previous runs.
*   `docs/PROTOCOL.v2.md`: Game protocol definition, including command schemas.
*   **Game Server Responses:** JSON messages received over the TCP connection, containing command results, errors, and game state updates.
*   **LLM Suggestions:** JSON command objects generated by the Ollama LLM for strategic planning or error recovery. This now also includes LLM-generated analysis and suggested commands for bug reports.

**Transformations:**
1.  **`GameConnection.read_responses()`**: Decodes raw TCP data into JSON response objects.
2.  **`process_responses()` (in `main.py`)**:
    *   Updates `StateManager` with latest game state (e.g., `session_token`, `player_location_sector`, `ship_info`, `current_credits`, `bank_balance`, `price_cache`).
    *   Handles specific error codes (e.g., 1403, 1307, 1405) by updating state or setting cooldowns.
    *   For unhandled errors, it triggers an LLM call for recovery. If the LLM provides a suggested command, it's stored in `llm_recovery_command`. If LLM recovery fails, a bug is reported via `BugReporter`, which will now deduplicate the bug, generate a regression test script, and potentially include LLM analysis and a suggested command in the markdown report.
3.  **`calculate_and_apply_reward()` (in `main.py`)**:
    *   Calculates a reward based on credit changes, trade profit/loss, and exploration events.
    *   Adds bonus rewards for `new_sector_discovered`, `new_port_discovered`.
    *   Crucially, incorporates `(last_trade_revenue - last_trade_cost)` into the reward, providing direct feedback on trade profitability.
    *   Updates the `BanditPolicy`'s Q-values for the `last_action` in the `last_context_key`.
    *   Resets trade-related flags and values.
4.  **`FiniteStatePlanner.get_next_command()`**:
    *   Determines the bot's current `stage`.
    *   Filters candidate actions based on preconditions and cooldowns.
    *   If in `exploit` stage, may consult LLM for strategic command suggestions.
    *   Uses `BanditPolicy.choose_action()` to select an action based on learned Q-values and exploration.
    *   Constructs the command payload using the appropriate payload builder (e.g., `_buy_payload`, `_warp_payload`).
    *   Validates the payload against cached schemas.
    *   If no command is generated by the planner, it attempts LLM recovery (using `RECOVERY_STUCK` stage prompt).
5.  **`GameConnection.send_command()`**: Encodes the JSON command object and sends it over TCP to the game server.

**Outputs:**
*   **Game Server Commands:** JSON messages sent over the TCP connection to interact with the game world.
*   `ai_player.log`: Detailed log of bot operations, decisions, and server interactions.
*   `state.json`: Updated persistent bot state.
*   `bugs/*.md`: Markdown files detailing reported bugs and invariant failures, now potentially including LLM analysis and regression test file paths.
*   `bugs/regression_tests/*.py`: Python scripts generated by `BugReporter` to replay bug-inducing command sequences.

## 4. Notable Patterns

*   **Finite State Machine (FSM):** The `FiniteStatePlanner` explicitly manages the bot's behavior through distinct stages (bootstrap, survey, explore, exploit). Transitions between these stages are based on game state and objectives.
*   **Reinforcement Learning (Multi-Armed Bandit):** The `BanditPolicy` implements an epsilon-greedy multi-armed bandit algorithm. This allows the AI to learn optimal actions within specific contexts (defined by `make_context_key`) by balancing exploration of new actions with exploitation of known rewarding actions.
*   **Event-Driven / Message-Driven:** The core loop is driven by incoming server responses. Responses trigger state updates, reward calculations, and subsequent planning decisions.
*   **Dependency Injection:** Components like `StateManager`, `GameConnection`, `Config`, `BugReporter`, and `BanditPolicy` are injected into the `FiniteStatePlanner`, promoting modularity and testability.
*   **LLM Integration:** The system uses an LLM (Ollama) for higher-level strategic suggestions in the `exploit` stage and for dynamic recovery from unhandled errors. Crucially, the `BugReporter` now leverages the LLM to provide automated analysis and suggested fixes for newly discovered bugs, acting as a "meta-planner" or "recovery agent" for the bug reporting process itself.

---

## High-Level Summary of the Entire Program

The AI_QA bot is an autonomous agent designed to interact with the TWClone game server. Its primary goal is to explore the game universe, discover commands and their schemas, gather information about sectors and ports, and engage in economic activities (buying and selling commodities) to maximize its credits. It employs a finite state planner for high-level decision-making, a multi-armed bandit algorithm for learning optimal actions within contexts, and an LLM for strategic guidance and dynamic error recovery. The bot logs its activities, persists its state, and now features enhanced bug reporting with deduplication, automated regression test generation, and LLM-powered analysis and suggested commands for bugs.

## Detailed Walk-Through of the Main Execution Path

1.  **Initialization (`main()` function):**
    *   Loads `config.json` for parameters like game host/port, log file, state file, LLM model, QA mode settings, and bandit policy parameters.
    *   Sets up logging and a `SIGINT` handler for graceful shutdown.
    *   Instantiates `StateManager`, `BugReporter`, `GameConnection`, `BanditPolicy`, and `FiniteStatePlanner`.
    *   Loads command schemas from `PROTOCOL.v2.md` into the `StateManager`'s cache.

2.  **Main Loop (`while not shutdown_flag`):**
    *   **Connection Check:** Ensures an active connection to the game server. If not, attempts reconnection with exponential backoff.
    *   **Response Processing (`process_responses`):**
        *   Reads all available messages from the game server.
        *   For each response:
            *   Updates `last_server_response` in `StateManager`.
            *   Appends to `last_responses_history`.
            *   Updates rate limit information.
            *   Matches `reply_to_id` to a `pending_command` to identify the command that triggered the response.
            *   If `status == "ok"`:
                *   Updates game state based on response type (e.g., `session_token`, `player_location_sector`, `ship_info`, `cargo`, `current_credits`, `bank_balance`, `sector_data`, `port_info_by_sector`, `price_cache`).
                *   Sets flags like `new_sector_discovered`, `trade_successful`, `new_port_discovered`.
            *   If `status != "ok"` (error/refused):
                *   Handles specific error codes:
                    *   `1403` (Insufficient cargo space): Forces `ship.info` refresh.
                    *   `1307` (Out of turns): Sets `waiting_for_turns = True` and `next_allowed_action_time` for a 1-hour cooldown.
                    *   `1405` (Port not buying commodity): Marks commodity as unsellable in `price_cache` for a cooldown.
                *   For any *other* error code, it logs the error and calls the LLM (via `get_ollama_response` with `UNHANDLED_ERROR_RECOVERY` stage) to suggest a recovery command, storing it in `llm_recovery_command`. If LLM recovery fails, it falls back to bug reporting via `BugReporter`. The `BugReporter` will now deduplicate the bug, generate a regression test script, and potentially include LLM analysis and a suggested command in the markdown report.
    *   **Reward Calculation (`calculate_and_apply_reward`):**
        *   Calculates a reward based on credit changes, trade profit/loss, and exploration events.
        *   Adds bonus rewards for `new_sector_discovered`, `new_port_discovered`.
        *   Crucially, incorporates `(last_trade_revenue - last_trade_cost)` into the reward, providing direct feedback on trade profitability.
        *   Updates the `BanditPolicy`'s Q-values for the `last_action` in the `last_context_key`.
        *   Resets trade-related flags and values.
    *   **Turns Cooldown Check:** If `waiting_for_turns` is `True` and `time.time() < next_allowed_action_time`, the bot sleeps for the remaining cooldown duration and `continues` the loop, effectively pausing.
    *   **Command Generation (`planner.get_next_command`):**
        *   **LLM Recovery Priority:** If `llm_recovery_command` is present (from an unhandled error), it's used as the `next_command_dict` and then cleared.
        *   **Planner Logic:** Otherwise, `planner.get_next_command()` is called:
            *   Determines the current `stage` (bootstrap, survey, explore, exploit) based on state invariants (e.g., no session token -> bootstrap; no ship info -> force ship.info).
            *   If in `exploit` stage, it calls `_find_best_trade_route` to identify profitable opportunities.
            *   Filters `action_catalogue` for the current stage based on preconditions (e.g., `_can_buy`, `_can_sell`, `_can_warp`, `_can_deposit`, `_can_withdraw`, cooldowns).
            *   If `holds_full` and `_can_sell` is true, it prioritizes a `trade.sell` command.
            *   If an `llm_suggestion` (from `exploit` stage) is provided and valid, it's used.
            *   Otherwise, `bandit_policy.choose_action()` selects the next command from the filtered candidates based on learned Q-values and exploration.
            *   Constructs the command payload using the appropriate payload builder (e.g., `_buy_payload`, `_warp_payload`).
            *   Validates the payload against cached schemas.
            *   If no command is generated by the planner, it attempts LLM recovery (using `RECOVERY_STUCK` stage prompt).
    *   **Command Sending:** If a `next_command_dict` is obtained, it's augmented with `id`, `ts`, `auth`, and `meta` fields (including idempotency key) and sent via `game_conn.send_command()`.
    *   **History Update:** The sent command is added to `last_commands_history`.
    *   **Loop Delay:** A small `time.sleep(0.5)` prevents excessive CPU usage.
    *   **Exception Handling:** Catches unhandled exceptions in the main loop, logs them, and introduces a delay before continuing.

## Key Data Structures and Algorithms

*   **`StateManager` (`state` dictionary):** A central dictionary holding the entire bot's mutable state. This includes:
    *   `session_token`, `player_location_sector`, `current_credits`, `bank_balance`.
    *   `ship_info` (details about the player's ship, including cargo and holds).
    *   `sector_data` (cached information about visited sectors, including ports and adjacencies).
    *   `port_info_by_sector` (detailed information about ports in visited sectors).
    *   `price_cache` (buy/sell prices for commodities at various ports, with timestamps).
    *   `q_table`, `n_table` (for the bandit policy).
    *   `last_commands_history`, `last_responses_history`.
    *   `pending_commands` (commands sent but awaiting a response).
    *   `broken_commands` (commands that consistently fail).
    *   `command_retry_info` (failure counts and next retry times for commands).
    *   `waiting_for_turns`, `next_allowed_action_time`, `llm_recovery_command`.
    *   `deduplicated_bugs`: A dictionary storing hashes of reported bugs to prevent duplicate entries.
*   **`BanditPolicy` (Multi-Armed Bandit):**
    *   **Epsilon-Greedy:** Balances exploration (random action selection) and exploitation (selecting the action with the highest estimated reward).
    *   **Q-Learning (Incremental Update):** `Q(a) = Q(a) + alpha * (reward - Q(a))` where `alpha = 1/N(a)`. This updates the estimated value of an action based on observed rewards.
    *   **Contextual Bandits:** Actions are learned within specific contexts (e.g., `stage:exploit-sector_class:unknown_class-port_type:port_present`), allowing for more nuanced decision-making.
*   **Finite State Planner:** Implements a state-based control flow, ensuring the bot progresses logically through different phases of operation (bootstrap, survey, explore, exploit).
*   **JSON Schema Validation:** Used to validate outgoing command payloads against expected schemas, preventing malformed requests to the server.
*   **LLM (Ollama):** Employed for:
    *   **Strategic Planning:** Providing high-level command suggestions in complex stages like `exploit`.
    *   **Error Recovery:** Dynamically suggesting commands to recover from unhandled server errors or getting stuck.
    *   **Bug Analysis:** Providing automated analysis and suggested commands within bug reports generated by `BugReporter`.

## External Dependencies and Side Effects

*   **External Dependencies:**
    *   `socket`: For TCP communication with the game server.
    *   `json`: For serializing/deserializing JSON messages.
    *   `time`, `datetime`: For timestamps and delays.
    *   `uuid`: For generating unique command IDs and idempotency keys.
    *   `ollama`: Python client for interacting with the Ollama LLM.
    *   `logging`: For structured logging.
    *   `os`, `signal`, `sys`, `argparse`, `random`: Standard Python libraries.
    *   `jsonschema`: For validating command payloads.
*   **Side Effects:**
    *   **Network I/O:** Sends and receives data from the game server.
    *   **File I/O:** Reads `config.json`, `PROTOCOL.v2.md`, `state.json`. Writes to `ai_player.log`, `state.json`, `bugs/*.md`, and `bugs/regression_tests/*.py`.
    *   **Game State Modification:** Actions taken by the bot modify the game state (e.g., ship location, cargo, credits).
    *   **LLM API Calls:** Makes HTTP requests to the local Ollama server.

## Risks, Edge Cases, and Concrete Improvement Suggestions

**Risks:**

*   **LLM Hallucinations/Bad Suggestions:** The LLM might suggest invalid or counterproductive commands, especially in recovery scenarios or bug analysis. The current payload validation mitigates this for known schemas, but the LLM could still suggest semantically incorrect but syntactically valid commands.
*   **Stuck States:** Despite recovery mechanisms, the bot could enter unforeseen loops or states where it cannot make progress (e.g., no valid actions, repeated unhandled errors).
*   **Economic Instability:** Aggressive trading or poor learning could lead to rapid credit loss, making the bot unable to perform actions.
*   **Rate Limiting:** While basic rate limit handling is present, complex server-side rate limiting could still cause issues if not precisely modeled.
*   **Protocol Changes:** Changes to the game protocol (commands, schemas, error codes) would break the bot's parsing and validation logic.

**Edge Cases:**

*   **Empty Sectors/Ports:** Sectors with no adjacent sectors or ports, or ports with no commodities. The current `_warp_payload` has some handling for dead ends.
*   **Zero Credits/Full Cargo:** Handled by preconditions for `trade.buy` and `trade.sell`.
*   **Server Disconnects:** Handled by `GameConnection`'s reconnection logic.
*   **No Profitable Trades:** The bot will fall back to exploration if no profitable trade routes are found.
*   **LLM Unavailability/Failure:** If the Ollama server is down or returns malformed responses, the bot's LLM-driven recovery and bug analysis will fail, potentially leading to a stuck state or less informative bug reports.

**Concrete Improvement Suggestions:**

1.  **Enhanced Trade Route Planning:**
    *   **Multi-hop Routes:** Implement logic to find profitable routes spanning multiple sectors (e.g., buy in A, warp to B, sell in B). The current `_find_best_trade_route` is single-hop.
    *   **Dynamic Quantity Calculation:** Instead of fixed quantities (e.g., `min(10, free_holds)`), calculate optimal buy/sell quantities based on profit margin, available credits, and holds.
    *   **Risk Assessment:** Incorporate commodity volatility into trade decisions. Avoid highly volatile commodities if the bot is risk-averse.
    *   **Market Manipulation:** (Advanced) If multiple bots are running, coordinate or compete for resources.

2.  **Sophisticated Exploration Strategy:**
    *   **Graph-based Exploration:** Use graph algorithms (e.g., Dijkstra's, A*) to find optimal paths to unexplored or high-value sectors, rather than just adjacent ones.
    *   **Information Value:** Prioritize exploring sectors that are likely to yield new information (e.g., unknown sectors, sectors with many adjacent unvisited sectors).

3.  **Improved LLM Integration:**
    *   **Structured LLM Output:** Enforce stricter JSON schema for LLM output to reduce parsing errors and ensure valid commands.
    *   **Contextual Prompts:** Provide more detailed and dynamic context to the LLM, including recent actions, errors, and specific goals, to improve the quality of its suggestions.
    *   **LLM for Precondition/Payload Generation:** Potentially use the LLM to generate preconditions or payload data for complex commands, reducing hardcoded logic.

4.  **Robust Error Handling and Recovery:**
    *   **Error Classification:** Categorize errors more granularly (e.g., transient vs. permanent, recoverable vs. unrecoverable) to inform recovery strategies.
    *   **Adaptive Cooldowns:** Implement dynamic cooldowns for specific errors or commands based on observed server behavior.
    *   **Circuit Breaker Pattern:** Temporarily disable commands that repeatedly fail to prevent spamming the server.

5.  **Learning Enhancements:**
    *   **UCB1 Bandit Policy:** Implement the UCB1 algorithm (already partially sketched in `bandit_policy.py`) for more effective exploration-exploitation, especially in early learning phases.
    *   **Deep Reinforcement Learning:** For more complex strategic decisions, consider a deeper RL approach if the state space becomes too large for tabular methods.
    *   **Hyperparameter Tuning:** Implement a mechanism to dynamically tune `epsilon` (and other bandit parameters) based on performance.

6.  **Resource Management:**
    *   **Fuel/Energy Management:** Incorporate fuel consumption into movement decisions.
    *   **Ship Upgrades:** Plan for and execute ship upgrades to improve cargo capacity, speed, or combat capabilities.

7.  **Testing and Simulation:**
    *   **Unit Tests:** Expand unit test coverage for planner logic, state transitions, and payload builders.
    *   **Simulation Environment:** Develop a local simulation environment to rapidly test and iterate on AI strategies without connecting to the live server.